{
	"llama-instruct": [
		[100000],
		{
			"max_generations": [3],
			"suggest_candidates": [true],
			"retrieve_paradigm": [true],
			"use_german_prompts": [true],
			"log_messages": [true]
		},
		"_SUKA"
	]
}